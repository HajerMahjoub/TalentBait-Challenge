{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"theApplication.ipynb","provenance":[],"authorship_tag":"ABX9TyNoq4eQwlyXO0062KqpOtus"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"s7bf1mZBKZL2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"7245528f-df45-4623-fe5d-b9916fd2e9ac","executionInfo":{"status":"ok","timestamp":1585064245927,"user_tz":-60,"elapsed":52353,"user":{"displayName":"Hajer Mahjoub","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibCmJm4I5alAYk2fdaQo4e-Il9gszBYLnB_f8Z5w=s64","userId":"16290332025867110084"}}},"source":["import pickle\n","import pandas as pd\n","import nltk\n","import nltk\n","nltk.download('stopwords')\n","print('------------')\n","nltk.download('punkt')\n","print('------------')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","\n","from nltk.tokenize import punkt\n","from nltk.corpus.reader import wordnet\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","!pip install 'dash==0.36'\n","import dash\n","import dash_core_components as dcc\n","import dash_html_components as html\n","import dash_table\n","from dash.dependencies import Input, Output, State\n","import plotly.graph_objs as go\n","import re\n","#Read the csv file from drive\n","!pip install -U -q PyDrive\n"," \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","------------\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","------------\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","Requirement already satisfied: dash==0.36 in /usr/local/lib/python3.6/dist-packages (0.36.0)\n","Requirement already satisfied: flask-compress in /usr/local/lib/python3.6/dist-packages (from dash==0.36) (1.4.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from dash==0.36) (4.4.1)\n","Requirement already satisfied: Flask>=0.12 in /usr/local/lib/python3.6/dist-packages (from dash==0.36) (1.1.1)\n","Requirement already satisfied: dash-renderer in /usr/local/lib/python3.6/dist-packages (from dash==0.36) (1.2.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly->dash==0.36) (1.12.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->dash==0.36) (1.3.3)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.12->dash==0.36) (2.11.1)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.12->dash==0.36) (1.0.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.12->dash==0.36) (7.1.1)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.12->dash==0.36) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.12->dash==0.36) (1.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q4ijOKYLK3Mv","colab_type":"code","colab":{}},"source":["#Load the best performing model\n","pickle_id = \"1zj05sWx5oUfQ1TCb2BUdL6UjHi2rfM3k\"\n","downloaded = drive.CreateFile({'id':pickle_id}) \n","downloaded.GetContentFile('best_lrc.pickle')\n","with open('best_lrc.pickle', 'rb') as data:\n","    lrc_model = pickle.load(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gKJBPYBMduL","colab_type":"code","colab":{}},"source":["#TFID Object\n","pickle_id = \"1OmkdxXkvCw67pg4DjMMWaazBNKNi_F8j\"\n","downloaded = drive.CreateFile({'id':pickle_id}) \n","downloaded.GetContentFile('tfidf.pickle')\n","with open('tfidf.pickle', 'rb') as data:\n","    tfidf = pickle.load(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bskq27aoMr_x","colab_type":"code","colab":{}},"source":["label_codes = {\n","    'none': 0,\n","    'soft': 1,\n","    'tech': 2,\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIyoomkcMwKQ","colab_type":"code","colab":{}},"source":["punctuation_signs = list(\"?:!.,;\")\n","stop_words = list(stopwords.words('english'))\n","\n","def create_features_from_text(text):\n","    \n","    # Dataframe creation\n","    lemmatized_text_list = []\n","    df = pd.DataFrame(columns=['Content'])\n","    df.loc[0] = text\n","    df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')\n","    df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()\n","    df['Content_Parsed_3'] = df['Content_Parsed_2']\n","    for punct_sign in punctuation_signs:\n","        df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n","    df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")\n","    wordnet_lemmatizer = WordNetLemmatizer()\n","    lemmatized_list = []\n","    text = df.loc[0]['Content_Parsed_4']\n","    text_words = text.split(\" \")\n","    for word in text_words:\n","        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n","    lemmatized_text = \" \".join(lemmatized_list)    \n","    lemmatized_text_list.append(lemmatized_text)\n","    df['Content_Parsed_5'] = lemmatized_text_list\n","    df['Content_Parsed_6'] = df['Content_Parsed_5']\n","    for stop_word in stop_words:\n","        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n","        df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n","    df = df['Content_Parsed_6']\n","    df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n","    \n","    # TF-IDF\n","    features = tfidf.transform(df).toarray()\n","    \n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZGGXWvRN4VV","colab_type":"code","colab":{}},"source":["def get_category_name(category_id):\n","    for category, id_ in label_codes.items():    \n","        if id_ == category_id:\n","            return category"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6DRRLqQOVvB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":537},"outputId":"6b9db2aa-ec69-42de-b55b-e96ae03dae1c","executionInfo":{"status":"error","timestamp":1585070706452,"user_tz":-60,"elapsed":1872,"user":{"displayName":"Hajer Mahjoub","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibCmJm4I5alAYk2fdaQo4e-Il9gszBYLnB_f8Z5w=s64","userId":"16290332025867110084"}}},"source":["# -*- coding: utf-8 -*-\n","import dash\n","import dash_core_components as dcc\n","import dash_html_components as html\n","from dash.dependencies import Input, Output\n","\n","external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\"]\n","\n","app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n","\n","app.layout = html.Div(\n","    [\n","        html.I(\"Try typing input and Press Enter \"),\n","        html.Br(),dcc.Input(id=\"input1\", type=\"text\"),\n","        html.Div(id=\"output\"),\n","    ]\n",")\n","\n","\n","@app.callback(\n","    Output(\"output\", \"children\"),\n","    [Input(\"input1\", \"value\")],\n",")\n","def update_output(input1):\n","  if input1 is not None and input1 is not '':\n","    try:\n","        prediction_lrc = lrc_model.predict(create_features_from_text(input1))[0]\n","        prediction_lrc_proba = lrc_model.predict_proba(create_features_from_text(input1))[0]\n","        category_lrc = get_category_name(prediction_lrc)\n","        pred =prediction_lrc_proba.max()*100 \n","        return 'The predicted category using the LRC model is {} \\n\\nThe conditional probability is: {}'.format(category_lrc,pred)\n","    except ValueError:\n","      return 'Error accured'\n","    \n","\n","\n","if __name__ == '__main__':\n","    app.run_server(debug=True)\n","\n","    \n","\n","  "],"execution_count":21,"outputs":[{"output_type":"stream","text":["Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Running on http://127.0.0.1:8050/\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n","Debugger PIN: 042-415-522\n"," * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: on\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning:\n","\n","To exit: use 'exit', 'quit', or Ctrl-D.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gqOrbgpgUD2F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
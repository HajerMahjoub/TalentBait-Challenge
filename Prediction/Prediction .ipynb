{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prediction .ipynb","provenance":[],"authorship_tag":"ABX9TyPOEUR9M0l7id+a9gtuFcf2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"oTpirNPVCOSN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"614abeaa-91bf-401f-bb5e-7cd99009ae51","executionInfo":{"status":"ok","timestamp":1585062676316,"user_tz":-60,"elapsed":4679,"user":{"displayName":"Hajer Mahjoub","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibCmJm4I5alAYk2fdaQo4e-Il9gszBYLnB_f8Z5w=s64","userId":"16290332025867110084"}}},"source":["import pickle\n","import pandas as pd\n","import nltk\n","import nltk\n","nltk.download('stopwords')\n","print('------------')\n","nltk.download('punkt')\n","print('------------')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","\n","from nltk.tokenize import punkt\n","from nltk.corpus.reader import wordnet\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","#Read the csv file from drive\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","------------\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","------------\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dkG5d8S_CfyC","colab_type":"code","colab":{}},"source":["pickle_id = \"1zj05sWx5oUfQ1TCb2BUdL6UjHi2rfM3k\"\n","downloaded = drive.CreateFile({'id':pickle_id}) \n","downloaded.GetContentFile('best_lrc.pickle')\n","with open('best_lrc.pickle', 'rb') as data:\n","    lrc_model = pickle.load(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YM-W3XQeDbln","colab_type":"code","colab":{}},"source":["#TFID Object\n","pickle_id = \"1OmkdxXkvCw67pg4DjMMWaazBNKNi_F8j\"\n","downloaded = drive.CreateFile({'id':pickle_id}) \n","downloaded.GetContentFile('tfidf.pickle')\n","with open('tfidf.pickle', 'rb') as data:\n","    tfidf = pickle.load(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhGuPnhyD6_X","colab_type":"code","colab":{}},"source":["label_codes = {\n","    'none': 0,\n","    'soft': 1,\n","    'tech': 2,\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lotFybVCEFDi","colab_type":"code","colab":{}},"source":["punctuation_signs = list(\"?:!.,;\")\n","stop_words = list(stopwords.words('english'))\n","\n","def create_features_from_text(text):\n","    \n","    # Dataframe creation\n","    lemmatized_text_list = []\n","    df = pd.DataFrame(columns=['Content'])\n","    df.loc[0] = text\n","    df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')\n","    df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()\n","    df['Content_Parsed_3'] = df['Content_Parsed_2']\n","    for punct_sign in punctuation_signs:\n","        df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n","    df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")\n","    wordnet_lemmatizer = WordNetLemmatizer()\n","    lemmatized_list = []\n","    text = df.loc[0]['Content_Parsed_4']\n","    text_words = text.split(\" \")\n","    for word in text_words:\n","        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n","    lemmatized_text = \" \".join(lemmatized_list)    \n","    lemmatized_text_list.append(lemmatized_text)\n","    df['Content_Parsed_5'] = lemmatized_text_list\n","    df['Content_Parsed_6'] = df['Content_Parsed_5']\n","    for stop_word in stop_words:\n","        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n","        df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n","    df = df['Content_Parsed_6']\n","    df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n","    \n","    # TF-IDF\n","    features = tfidf.transform(df).toarray()\n","    \n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9rhIDUCEasp","colab_type":"code","colab":{}},"source":["def get_category_name(category_id):\n","    for category, id_ in label_codes.items():    \n","        if id_ == category_id:\n","            return category"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9QBhgtjFycU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"d48e1e83-57d1-40b2-b5ef-44359079da87","executionInfo":{"status":"ok","timestamp":1585062894851,"user_tz":-60,"elapsed":447,"user":{"displayName":"Hajer Mahjoub","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibCmJm4I5alAYk2fdaQo4e-Il9gszBYLnB_f8Z5w=s64","userId":"16290332025867110084"}}},"source":["lrc_model"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=0.6444444444444444, class_weight='balanced', dual=False,\n","                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n","                   max_iter=100, multi_class='multinomial', n_jobs=None,\n","                   penalty='l2', random_state=8, solver='sag', tol=0.0001,\n","                   verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"qwb_6RVaE4qz","colab_type":"code","colab":{}},"source":["def predict_from_text(text):\n","    \n","    # Predict using the input model\n","    prediction_lrc = lrc_model.predict(create_features_from_text(text))[0]\n","    prediction_lrc_proba = lrc_model.predict_proba(create_features_from_text(text))[0]\n","    \n","    # Return result\n","    category_lrc = get_category_name(prediction_lrc)\n","    \n","    print(\"The predicted category using the LRC model is %s.\" %(category_lrc) )\n","    print(\"The conditional probability is: %a\" %(prediction_lrc_proba.max()*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QeB6yL5PFQIc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e800bc10-b66b-47d8-f0fe-d5b021effa71","executionInfo":{"status":"ok","timestamp":1585062922387,"user_tz":-60,"elapsed":887,"user":{"displayName":"Hajer Mahjoub","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibCmJm4I5alAYk2fdaQo4e-Il9gszBYLnB_f8Z5w=s64","userId":"16290332025867110084"}}},"source":["text=\"Kreativität und schnelle Auffassungsgabe\"\n","predict_from_text(text)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["The predicted category using the LRC model is soft.\n","The conditional probability is: 89.9046668593414\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_wrF3Jq6Iyqm","colab_type":"text"},"source":["\n","**Conclusion for result**\n","\n","{\n","  \"label\":\"soft\",\n","  \"text\":\"Kreativität und schnelle Auffassungsgabe\"\n","}\n","\n","*Multinomial Logistic Regressio*n is the best model for our case of text classification\n","the model predict the text is Soft with conditional probability  90%"]},{"cell_type":"code","metadata":{"id":"-HrDXQRxFfX0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}